Once the skip-list is populated with the information about words, their frequency and their offsets, their selectivity for index is based on lookups of WordNet. WordNet is available in a set of a few text files â€“ about half of which stores the adjective, adverbs, noun and verbs while the other half stores the indexes corresponding to these. These data contain various annotations and metadata as well that will come useful in the lookups. Hence their translation and parsing may be required. The text files are also not very huge and are of the order of a few Megabytes.

Since the data is available in text files, they can be read once and stored entirely in-memory. With the help of a suitable data structure, the functionality for lookup can be implemented over these data structures..  There has been some work using Boost graph to implement fast lookups. The lookups are generally to find synsets of given words and then find the hierarchical information or distance information for similarity measurements. Both the boost graph as well as the APIs for the lookup of the information can be implemented in a separate C++ module.

In addition to the data structures, the code for lookup of word associations can be expanded and written in a separate module. This way the implementation for translation, parsing, lookup, comparisions, hierarchical traversal and even word group can form a layer over the representation of the data. Initially only the similarity measures lookup may be required for the purposes of the book indexing program, but keeping them in a separate layer as an API implementation will be helpful.
